{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN9QUbqNYcOxNrofBTds3q7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIKN2whuAH15"
      },
      "source": [
        "# Download and unzip database\n",
        "# !wget https://archive.ics.uci.edu/ml/machine-learning-databases/00240/UCI%20HAR%20Dataset.zip\n",
        "# !unzip \"UCI HAR Dataset.zip\"\n",
        "# !wget https://github.com/sjriek/AIS7/blob/main/HAR.zip \n",
        "!wget https://github.com/sjriek/AIS7/raw/main/HAR.zip\n",
        "!unzip HAR.zip\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoBGxVxSW7q5"
      },
      "source": [
        "# function to plot confusion matrix\n",
        "def plot_confusion_matrix(cm,lables):\n",
        "    fig, ax = plt.subplots(figsize=(15,5)) # for plotting confusion matrix as image\n",
        "    im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set(xticks=np.arange(cm.shape[1]),\n",
        "    yticks=np.arange(cm.shape[0]),\n",
        "    xticklabels=lables, yticklabels=lables,\n",
        "    ylabel='True label',\n",
        "    xlabel='Predicted label')\n",
        "    plt.xticks(rotation = 90)\n",
        "    plt.grid(b=False)\n",
        "    thresh = cm.max() / 2.\n",
        "    for i in range(cm.shape[0]):\n",
        "        for j in range(cm.shape[1]):\n",
        "            ax.text(j, i, int(cm[i, j]),ha=\"center\", va=\"center\",color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeLnYa_E7Yc7"
      },
      "source": [
        "# load dataset\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "\n",
        "# load a single file as a numpy array\n",
        "def load_file(filepath):\n",
        "\tdataframe = read_csv(filepath, header=None, delim_whitespace=True)\n",
        "\treturn dataframe.values\n",
        " \n",
        "# load a list of files, such as x, y, z data for a given variable\n",
        "def load_group(filenames, prefix=''):\n",
        "\tloaded = list()\n",
        "\tfor name in filenames:\n",
        "\t\tdata = load_file(prefix + name)\n",
        "\t\tloaded.append(data)\n",
        "\t# stack group so that features are the 3rd dimension\n",
        "\tloaded = dstack(loaded)\n",
        "\treturn loaded\n",
        " \n",
        "# load a dataset group, such as train or test\n",
        "def load_dataset(group, prefix=''):\n",
        "\tfilepath = prefix + group + '/Inertial Signals/'\n",
        "\t# load all 9 files as a single array\n",
        "\tfilenames = list()\n",
        "\t# total acceleration\n",
        "\tfilenames += ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
        "\t# body acceleration\n",
        "\tfilenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
        "\t# body gyroscope\n",
        "\tfilenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
        "\t# load input data\n",
        "\tX = load_group(filenames, filepath)\n",
        "\t# load class output\n",
        "\ty = load_file(prefix + group + '/y_'+group+'.txt')\n",
        "\treturn X, y\n",
        " \n",
        "# load all train\n",
        "X_train, y_train = load_dataset('train', 'UCI HAR Dataset/')\n",
        "print(X_train.shape, y_train.shape)\n",
        "# load all test\n",
        "X_test, y_test = load_dataset('test', 'UCI HAR Dataset/')\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1s2eD-S4TwoI"
      },
      "source": [
        "# load dataset\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "\n",
        "df_train = read_csv(\"./train.csv\")\n",
        "df_test = read_csv(\"./test.csv\")\n",
        "\n",
        "X_train, y_train = df_train.drop(['subject', 'Activity'], axis=1), df_train['Activity']\n",
        "X_test, y_test = df_test.drop(['subject', 'Activity'], axis=1), df_test['Activity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RlsT_noV9Vc"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = KNeighborsClassifier(3)\n",
        "# model = LogisticRegression(penalty='l2', C=10,solver='lbfgs',class_weight='balanced', max_iter=10000,random_state = 0)\n",
        "model.fit(X_train, y_train)\n",
        "score = model.score(X_test,y_test)\n",
        "print (score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4g04hyNWTGh"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predict = model.predict(X_test)\n",
        "confusion = confusion_matrix(y_test,predict)\n",
        "print(\"==== Confusion Matrix ===\")\n",
        "print(confusion)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "plot_confusion_matrix(confusion, np.unique(predict))\n",
        "#using matplotlib\n",
        "plt.matshow(confusion)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# def plotMatrix(data):\n",
        "#   fig, ax = plt.subplots()\n",
        "#   # Using matshow here just because it sets the ticks up nicely. imshow is faster.\n",
        "#   ax.matshow(data, cmap='viridis')\n",
        "#   for (i, j), z in np.ndenumerate(data):\n",
        "#      ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
        "#   plt.show()\n",
        "\n",
        "# plotMatrix(confusion)\n",
        "\n",
        "#using seaborn\n",
        "# from sklearn import metrics\n",
        "# cnf_matrix = metrics.confusion_matrix(y_test, predict)\n",
        "# p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True)\n",
        "\n",
        "\n",
        "\n",
        "#using pandas\n",
        "pd.DataFrame(confusion).style.background_gradient(cmap='viridis').set_precision(4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WHZ_NX-JpYP"
      },
      "source": [
        "nsamples, nx, ny = X_train.shape\n",
        "X2d_train = X_train.reshape((nsamples,nx*ny))\n",
        "\n",
        "nsamples, nx, ny = X_test.shape\n",
        "X2d_test = X_test.reshape((nsamples,nx*ny))\n",
        "\n",
        "print(X2d_train.shape, y_train.shape)\n",
        "\n",
        "print(X2d_test.shape, y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgMzLSO8Bv5J"
      },
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from pandas.plotting import scatter_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# model = KNeighborsClassifier(3)\n",
        "model = LogisticRegression(penalty='l2', C=10,solver='lbfgs',class_weight='balanced', max_iter=10000,random_state = 0)\n",
        "model.fit(X2d_train, y_train)\n",
        "score = model.score(X2d_test,y_test)\n",
        "print (score)\n",
        "# models = []\n",
        "\n",
        "# models.append(('SVM', SVC(gamma='auto')))\n",
        "# # models.append(('RFC', RandomForestClassifier(max_depth=5, n_estimators=40)))\n",
        "\n",
        "# results = []\n",
        "# names = []\n",
        "# scoring = 'accuracy'\n",
        "\n",
        "\n",
        "# for name, model in models:\n",
        "#   kfold = model_selection.KFold(n_splits=10)\n",
        "#   cv_results = model_selection.cross_val_score(model, X_train, y_train)\n",
        "#   print(cv_results)\n",
        "#   results.append(cv_results)\n",
        "#   names.append(name)\n",
        "#   msg = \"%s Algorithm: Accuracy %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "#   print(msg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNZs-SDaL0YH"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "predict = model.predict(X2d_test)\n",
        "confusion = confusion_matrix(y_test,predict)\n",
        "print(\"==== Confusion Matrix ===\")\n",
        "print(confusion)\n",
        "print('\\n')\n",
        "\n",
        "#using matplotlib\n",
        "# plt.matshow(confusion)\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# def plotMatrix(data):\n",
        "#   fig, ax = plt.subplots()\n",
        "#   # Using matshow here just because it sets the ticks up nicely. imshow is faster.\n",
        "#   ax.matshow(data, cmap='viridis')\n",
        "#   for (i, j), z in np.ndenumerate(data):\n",
        "#      ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center')\n",
        "#   plt.show()\n",
        "\n",
        "# plotMatrix(confusion)\n",
        "\n",
        "#using seaborn\n",
        "# from sklearn import metrics\n",
        "# cnf_matrix = metrics.confusion_matrix(y_test, predict)\n",
        "# p = sns.heatmap(pd.DataFrame(cnf_matrix), annot=True)\n",
        "\n",
        "\n",
        "\n",
        "#using pandas\n",
        "pd.DataFrame(cnf_matrix).style.background_gradient(cmap='viridis').set_precision(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CAR5D5lMwk7"
      },
      "source": [
        "X2d_test"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}